# -*- coding: utf-8 -*-
"""PFA_DL_MobileNetV2_IEP.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10U9uYm63Ks-qEElz90VdRyZUy4mrGjcc

**Master Inteligencia Artificial**

**Utilizando MobileNetV2**

**Tranfers Learning y Finne Tuning**
"""

# Importar librerías
import tensorflow as tf
import os
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D
from tensorflow.keras.applications import ResNet50, MobileNetV2
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Montar Google Drive
from google.colab import drive
drive.mount('/content/drive', force_remount=True)

# Directorios de datos
dataset_path = "drive/MyDrive/dataset_balanced"
train_dir = os.path.join(dataset_path, "train")
test_dir = os.path.join(dataset_path, "test")
val_dir = os.path.join(dataset_path, "val")

# Parámetros
img_size = (224, 224)
batch_size = 32
epochs = 30

# Data Augmentation para validación y prueba (solo rescale) valores entre 0 y 1rftg5
val_test_datagen = ImageDataGenerator(rescale=1.0 / 255.0)

# Configuración de Data Augmentation para entrenamiento, al tener pocos datos, aumentamos
train_datagen = ImageDataGenerator(
    rescale=1.0 / 255.0,         # Escalar valores de píxeles entre 0 y 1
    rotation_range=30,           # Rotaciones aleatorias
    width_shift_range=0.2,       # Desplazamiento horizontal
    height_shift_range=0.2,      # Desplazamiento vertical
    shear_range=0.2,             # Rotación aleatoria
    zoom_range=0.4,              # Zoom aleatorio
    horizontal_flip=True,         # Inversión horizontal
    vertical_flip=True,           # Inversión vertical
    fill_mode='nearest'
)

# Generadores de datos
# Generador actualizado para cargar todo el conjunto de entrenamiento
#train_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_dir,                   # La carpeta principal de entrenamiento
    target_size=img_size,      # Tamaño al que se redimensionan las imágenes
    batch_size=32,               # Tamaño de lote
    class_mode='categorical',     # Para clasificación multiclase
    shuffle=True
)

val_generator = val_test_datagen.flow_from_directory(
    val_dir,                     # Directorio de validación
    target_size=img_size,
    batch_size=32,
    class_mode='categorical',
    shuffle=False
)

# Opcional: Generador para datos de prueba
test_generator = val_test_datagen.flow_from_directory(
    test_dir,
    target_size=img_size,
    batch_size=32,
    class_mode='categorical',
    shuffle=False                # No barajar para evaluación
)

# Cargar el modelo base MobileNetV2 preentrenado
base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
base_model.trainable = False  # Congelar el modelo base

# Construcción del modelo
x = base_model.output

# GlobalAveragePooling en lugar de Flatten directamente para reducir dimensiones
x = GlobalAveragePooling2D()(x)

# Nuevas capas densas
x = Dense(128, activation='relu')(x)
x = Dropout(0.5)(x)
x = Dense(64, activation='relu')(x)
x = Dropout(0.5)(x)

# Capa de salida
predictions = Dense(3, activation='softmax')(x)

# Crear el modelo
model = Model(inputs=base_model.input, outputs=predictions)

# Compilar el modelo
model.compile(optimizer=Adam(learning_rate=0.0005),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Callbacks
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=3, min_lr=1e-6, verbose=1)
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

# Pesos de Clase (ajustar según el desbalance)
#class_weights = {0: 2.0, 1: 1.0, 2: 2.5}
#class_weights = {0: 1.0, 1: 1.5, 2: 2.0} fatal
class_weights = {0: 1.0, 1: 1.0, 2: 2.0}

# Entrenamiento del modelo
history = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=epochs,
    verbose=1,
)

model.save('modelo_COVID19.keras')

# Desbloquear las capas superiores del modelo base para el fine-tuning
base_model.trainable = True

# Opcional: Congelar capas inferiores para evitar sobreajuste
for layer in base_model.layers[:100]:  # Ajusta según tu modelo
    layer.trainable = False

# Evaluar el modelo en el conjunto de prueba
test_loss, test_accuracy = model.evaluate(test_generator)
print(f"Loss en Prueba: {test_loss:.4f}")
print(f"Accuracy en Prueba: {test_accuracy:.4f}")

# Generar reporte de clasificación
# Obtener predicciones
import numpy as np
from sklearn.metrics import classification_report, confusion_matrix
predictions = model.predict(test_generator)
y_pred = np.argmax(predictions, axis=1)
y_true = test_generator.classes

from sklearn.metrics import classification_report, confusion_matrix
import numpy as np

# Obtener predicciones
y_pred = model.predict(test_generator)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true = test_generator.classes  # Etiquetas reales

# Reporte de clasificación
print(classification_report(y_true, y_pred_classes, target_names=test_generator.class_indices.keys()))

# Matriz de confusión
cm = confusion_matrix(y_true, y_pred_classes)
print("Confusion Matrix:")
print(cm)

import seaborn as sns
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt

y_pred = model.predict(test_generator)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true = test_generator.classes

cm = confusion_matrix(y_true, y_pred_classes)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=test_generator.class_indices.keys(), yticklabels=test_generator.class_indices.keys())
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Matriz de Confusión')
plt.show()

# Crear dos gráficos en la misma figura
import matplotlib.pyplot as plt
fig, axs = plt.subplots(1, 2, figsize=(12, 4))

# Pérdida
axs[0].plot(history.history['loss'], label='Training Loss')
axs[0].plot(history.history['val_loss'], label='Validation Loss')
axs[0].set_title('Loss over epochs')
axs[0].set_xlabel('Epochs')
axs[0].set_ylabel('Loss')
axs[0].legend()

# Precisión
axs[1].plot(history.history['accuracy'], label='Training Accuracy')
axs[1].plot(history.history['val_accuracy'], label='Validation Accuracy')
axs[1].set_title('Accuracy over epochs')
axs[1].set_xlabel('Epochs')
axs[1].set_ylabel('Accuracy')
axs[1].legend()

plt.tight_layout()
plt.show()

"""**Informe de Resultados: MobileNetV2**

Se evaluó el rendimiento de un modelo basado en MobileNetV2 para la clasificación de imágenes en tres categorías: Covid, Normal y Viral Pneumonia. A continuación, se detallan los resultados principales:

Métricas de Clasificación
	•	Covid: Se obtuvo un F1-score de 0.93, con una precisión de 87% y un recall perfecto de 100%, indicando un excelente rendimiento en esta clase.
	•	Normal: Mostró un F1-score de 0.78, con una precisión de 69% y un recall de 90%, lo que evidencia un número moderado de falsos positivos.
	•	Viral Pneumonia: Fue la clase más problemática, con un F1-score de 0.53, precisión de 80%, pero un recall bajo de 40%, reflejando dificultades para identificar correctamente esta categoría.

Métricas Globales
	•	Accuracy: El modelo logró una exactitud general del 79%.
	•	Macro avg: El F1-score promedio no ponderado fue 0.75, lo que sugiere un rendimiento desigual entre clases.
	•	Weighted avg: El F1-score ponderado por soporte fue 0.76.

Matriz de Confusión

El modelo clasificó correctamente:
	•	Covid: 26/26 casos.
	•	Normal: 18/20 casos.
	•	Viral Pneumonia: Solo 8/20 casos, con errores significativos al confundirla con las otras clases.

Conclusión

MobileNetV2 mostró un buen desempeño en general, destacándose en la clasificación de la clase Covid, pero con margen de mejora para Viral Pneumonia, que presentó el menor recall y la mayor confusión. Se recomienda ajustar el modelo mediante técnicas como aumento de datos, oversampling para clases minoritarias o ajustes en los hiperparámetros para equilibrar mejor las clases.
"""